{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the dataset\n",
    "def read_dataset(file_path):\n",
    "    \"\"\"\n",
    "    Load the dataset from a CSV file.\n",
    "    :param file_path: Path to the CSV file.\n",
    "    :return: Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    dataset = pd.read_csv(file_path, dtype=str, index_col = 0)\n",
    "    print(f\"Dataset loaded. Shape: {dataset.shape}\")\n",
    "    print(dataset.head(10))\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. Shape: (97966, 3)\n",
      "                 Gender    Number       Lemma\n",
      "Word                                         \n",
      "a-humain      masculine  singular    a-humain\n",
      "a-raciste     masculine  singular   a-raciste\n",
      "aalénien      masculine  singular    aalénien\n",
      "aaléniens     masculine    plural    aalénien\n",
      "aalénienne     feminine  singular    aalénien\n",
      "aaléniennes    feminine    plural    aalénien\n",
      "aaronide      masculine  singular    aaronide\n",
      "abactérien    masculine  singular  abactérien\n",
      "abactériens   masculine    plural  abactérien\n",
      "abactérienne   feminine  singular  abactérien\n"
     ]
    }
   ],
   "source": [
    "# File path to the adj aset\n",
    "file_path = r\"C:\\Users\\user1\\Desktop\\HarvestWE-main\\HarvestWE-main\\Data\\Morphalou\\all_adjs_v2.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "adjs = read_dataset(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Number</th>\n",
       "      <th>Lemma</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a-humain</th>\n",
       "      <td>masculine</td>\n",
       "      <td>singular</td>\n",
       "      <td>a-humain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a-raciste</th>\n",
       "      <td>masculine</td>\n",
       "      <td>singular</td>\n",
       "      <td>a-raciste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aalénien</th>\n",
       "      <td>masculine</td>\n",
       "      <td>singular</td>\n",
       "      <td>aalénien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaléniens</th>\n",
       "      <td>masculine</td>\n",
       "      <td>plural</td>\n",
       "      <td>aalénien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aalénienne</th>\n",
       "      <td>feminine</td>\n",
       "      <td>singular</td>\n",
       "      <td>aalénien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>œstroprogestatives</th>\n",
       "      <td>feminine</td>\n",
       "      <td>plural</td>\n",
       "      <td>œstroprogestatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>œuvé</th>\n",
       "      <td>masculine</td>\n",
       "      <td>singular</td>\n",
       "      <td>œuvé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>œuvés</th>\n",
       "      <td>masculine</td>\n",
       "      <td>plural</td>\n",
       "      <td>œuvé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>œuvée</th>\n",
       "      <td>feminine</td>\n",
       "      <td>singular</td>\n",
       "      <td>œuvé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>œuvées</th>\n",
       "      <td>feminine</td>\n",
       "      <td>plural</td>\n",
       "      <td>œuvé</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67982 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Gender    Number             Lemma\n",
       "Word                                                     \n",
       "a-humain            masculine  singular          a-humain\n",
       "a-raciste           masculine  singular         a-raciste\n",
       "aalénien            masculine  singular          aalénien\n",
       "aaléniens           masculine    plural          aalénien\n",
       "aalénienne           feminine  singular          aalénien\n",
       "...                       ...       ...               ...\n",
       "œstroprogestatives   feminine    plural  œstroprogestatif\n",
       "œuvé                masculine  singular              œuvé\n",
       "œuvés               masculine    plural              œuvé\n",
       "œuvée                feminine  singular              œuvé\n",
       "œuvées               feminine    plural              œuvé\n",
       "\n",
       "[67982 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjs = adjs[(adjs.Gender != 'invariable') & (adjs.Number != 'invariable')]\n",
    "adjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode features\n",
    "def encode_feature(feature):\n",
    "    \"\"\"\n",
    "    Encode categorical features as numeric values.\n",
    "    :param feature: Pandas Series to encode.\n",
    "    :return: Encoded feature.\n",
    "    \"\"\"\n",
    "    le = LabelEncoder()\n",
    "    le.fit(feature.unique())\n",
    "    feature_encoded = le.transform(feature)\n",
    "    return feature_encoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset, feature_name, encode_as1=None, normalize_columns=None, remove_original=False):\n",
    "    \"\"\"\n",
    "    Preprocess the dataset by encoding features and normalizing specified columns.\n",
    "    :param dataset: Input DataFrame.\n",
    "    :param feature_name: The feature to encode as binary.\n",
    "    :param encode_as1: Map one of the feature's values to 1, others to 0.\n",
    "    :param normalize_columns: List of columns to normalize.\n",
    "    :param remove_original: Whether to remove the original categorical column.\n",
    "    :return: Preprocessed DataFrame.\n",
    "    \"\"\"\n",
    "    # Encode Gender\n",
    "    if encode_as1:\n",
    "        dataset[f\"{feature_name}_encoded\"] = (dataset[feature_name] == encode_as1).astype(int)\n",
    "    else:\n",
    "        dataset[f\"{feature_name}_encoded\"] = encode_feature(dataset[feature_name])\n",
    "\n",
    "    print(f\"Feature '{feature_name}' encoded. Sample:\")\n",
    "    print(dataset[[feature_name, f\"{feature_name}_encoded\"]].head(10))\n",
    "    \n",
    "    # Normalize specified columns\n",
    "    if normalize_columns:\n",
    "        scaler = MinMaxScaler()\n",
    "        dataset[normalize_columns] = scaler.fit_transform(dataset[normalize_columns])\n",
    "        print(f\"Columns normalized: {normalize_columns}\")\n",
    "        print(dataset[normalize_columns].head(5))\n",
    "    \n",
    "    # Remove original categorical column if specified\n",
    "    if remove_original:\n",
    "        dataset = dataset.drop(columns=[feature_name])\n",
    "        print(f\"Original feature '{feature_name}' removed.\")\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 'Gender' encoded. Sample:\n",
      "                 Gender  Gender_encoded\n",
      "Word                                   \n",
      "a-humain      masculine               1\n",
      "a-raciste     masculine               1\n",
      "aalénien      masculine               1\n",
      "aaléniens     masculine               1\n",
      "aalénienne     feminine               0\n",
      "aaléniennes    feminine               0\n",
      "aaronide      masculine               1\n",
      "abactérien    masculine               1\n",
      "abactériens   masculine               1\n",
      "abactérienne   feminine               0\n",
      "Original feature 'Gender' removed.\n"
     ]
    }
   ],
   "source": [
    "adjs_cleaned = preprocess_dataset(\n",
    "    dataset=adjs,\n",
    "    feature_name='Gender',\n",
    "    encode_as1='masculine',\n",
    "    normalize_columns=None,\n",
    "    remove_original=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Number             Lemma  Gender_encoded\n",
      "Word                                                          \n",
      "a-humain            singular          a-humain               1\n",
      "a-raciste           singular         a-raciste               1\n",
      "aalénien            singular          aalénien               1\n",
      "aaléniens             plural          aalénien               1\n",
      "aalénienne          singular          aalénien               0\n",
      "...                      ...               ...             ...\n",
      "œstroprogestatives    plural  œstroprogestatif               0\n",
      "œuvé                singular              œuvé               1\n",
      "œuvés                 plural              œuvé               1\n",
      "œuvée               singular              œuvé               0\n",
      "œuvées                plural              œuvé               0\n",
      "\n",
      "[67982 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the updated DataFrame\n",
    "print(adjs_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Number             Lemma  Gender_encoded\n",
      "Word                                                          \n",
      "a-humain            singular          a-humain               1\n",
      "a-raciste           singular         a-raciste               1\n",
      "aalénien            singular          aalénien               1\n",
      "aaléniens             plural          aalénien               1\n",
      "aalénienne          singular          aalénien               0\n",
      "...                      ...               ...             ...\n",
      "œstroprogestatives    plural  œstroprogestatif               0\n",
      "œuvé                singular              œuvé               1\n",
      "œuvés                 plural              œuvé               1\n",
      "œuvée               singular              œuvé               0\n",
      "œuvées                plural              œuvé               0\n",
      "\n",
      "[67982 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(adjs_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Word', 'Number', 'Lemma', 'Gender_encoded'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "adjs_cleaned = adjs_cleaned.reset_index()\n",
    "\n",
    "print(adjs_cleaned.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjs_cleaned.to_csv(\"cleaned_adjs_gender.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "class WENotFound(Exception):\n",
    "    \"\"\"Exception raised when a word embedding is not found.\"\"\"\n",
    "    pass\n",
    "\n",
    "# Function to load model and tokenizer\n",
    "def load_model_and_tokenizer(model_name):\n",
    "    \"\"\"\n",
    "    Load a pre-trained masked language model and its tokenizer.\n",
    "    :param model_name: Name of the pre-trained model.\n",
    "    :return: Model and tokenizer objects.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "    return model, tokenizer\n",
    "\n",
    "# Function to get word embedding\n",
    "def get_we(model, tokenizer, word):\n",
    "    \"\"\"\n",
    "    Extract the embedding for a single word.\n",
    "    :param model: Pre-trained model.\n",
    "    :param tokenizer: Tokenizer corresponding to the model.\n",
    "    :param word: Word to extract embedding for.\n",
    "    :return: Numpy array containing the word embedding.\n",
    "    \"\"\"\n",
    "    encoding = tokenizer.encode(word)\n",
    "    if len(encoding) != 3:  # Word should be encoded as a single token\n",
    "        raise WENotFound(f'{word}: the word doesn\\'t exist in the vocab')\n",
    "\n",
    "    word_id = encoding[1]  # Extract the actual word token ID\n",
    "    token_ids = torch.tensor([[word_id]])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(token_ids, output_hidden_states=True)\n",
    "        last_layer_hidden_states = outputs.hidden_states[-1]\n",
    "\n",
    "    return last_layer_hidden_states.squeeze().numpy()\n",
    "\n",
    "# Function to generate embeddings for all words in dataset\n",
    "def generate_embeddings(words_df, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Generate embeddings for a list of words.\n",
    "    :param words_df: DataFrame containing words and their labels.\n",
    "    :param model: Pre-trained language model.\n",
    "    :param tokenizer: Corresponding tokenizer.\n",
    "    :return: DataFrame with word embeddings.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    skipped_words = []\n",
    "\n",
    "    for _, row in words_df.iterrows():\n",
    "        word = row[\"Word\"]\n",
    "        gender = row[\"Gender_encoded\"]\n",
    "\n",
    "        try:\n",
    "            word_embedding = get_we(model, tokenizer, word)\n",
    "            word_dict = {x[0]: x[1] for x in enumerate(word_embedding)}\n",
    "            word_dict['Word'] = word\n",
    "            word_dict['Gender'] = gender\n",
    "            embeddings.append(word_dict)\n",
    "\n",
    "        except WENotFound:\n",
    "            skipped_words.append(word)\n",
    "\n",
    "    print(f\"Skipped words due to out-of-vocabulary: {len(skipped_words)}\")\n",
    "    emb_df = pd.DataFrame(embeddings)\n",
    "    return emb_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing embeddings for XLM-R_largeon adjectives...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped words due to out-of-vocabulary: 67087\n",
      "Sample embeddings for XLM-R_large:\n",
      "                   0         1         2         3         4         5  \\\n",
      "Word                                                                     \n",
      "abdominal  -0.035306 -0.068203  0.302270 -0.129037  0.472714 -0.213675   \n",
      "abrupt      0.056057 -0.144392  0.012552 -0.372142 -0.091922  0.136170   \n",
      "absent      0.131544 -0.391886 -0.075089 -0.358459 -0.235885  0.342959   \n",
      "accepté     0.109618 -0.327010  0.183316 -0.358990 -0.368958  0.297833   \n",
      "accompagné  0.080698  0.002290  0.134187  0.133029 -0.032265 -0.123115   \n",
      "\n",
      "                   6         7         8         9  ...      1015      1016  \\\n",
      "Word                                                ...                       \n",
      "abdominal  -0.502867  0.159517 -0.176921 -0.145372  ...  0.047238  0.332361   \n",
      "abrupt     -0.534903  0.105950  0.042881 -0.218313  ...  0.547907 -0.288354   \n",
      "absent     -0.024962 -0.320995  0.165644 -0.124614  ... -0.088018 -0.307133   \n",
      "accepté    -0.389703 -0.573842  0.098828 -0.120189  ...  0.060607  0.066084   \n",
      "accompagné  0.178873  0.044993  0.101974 -0.010939  ... -0.083464  0.072196   \n",
      "\n",
      "                1017      1018      1019      1020      1021      1022  \\\n",
      "Word                                                                     \n",
      "abdominal  -0.166508 -0.159517 -0.020466 -0.073194 -0.063935  0.098172   \n",
      "abrupt     -0.090236  0.107257  0.191245 -0.010051  0.676668  0.155957   \n",
      "absent     -0.409979  0.199112  0.110467 -0.145308  0.622773  0.179615   \n",
      "accepté    -0.222383  0.294254 -0.193770 -0.179569  0.480231  0.157466   \n",
      "accompagné  0.023241  0.052021  0.060979 -0.052586  0.149786 -0.082537   \n",
      "\n",
      "                1023  Gender  \n",
      "Word                          \n",
      "abdominal  -0.089008       1  \n",
      "abrupt     -0.118264       1  \n",
      "absent     -0.017885       1  \n",
      "accepté    -0.246653       1  \n",
      "accompagné  0.103895       1  \n",
      "\n",
      "[5 rows x 1025 columns]\n",
      "Saved adjective embeddings for XLM-R_large.\n",
      "Processing embeddings for XLM-Roberta-Baseon adjectives...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped words due to out-of-vocabulary: 67087\n",
      "Sample embeddings for XLM-Roberta-Base:\n",
      "                   0         1         2         3         4         5  \\\n",
      "Word                                                                     \n",
      "abdominal   0.076337  0.100679  0.046470 -0.019452  0.041524 -0.025531   \n",
      "abrupt      0.076337  0.100678  0.046473 -0.019451  0.041521 -0.025532   \n",
      "absent      0.076339  0.100679  0.046480 -0.019451  0.041518 -0.025530   \n",
      "accepté     0.076339  0.100682  0.046480 -0.019450  0.041519 -0.025530   \n",
      "accompagné  0.076339  0.100680  0.046480 -0.019450  0.041518 -0.025530   \n",
      "\n",
      "                   6         7         8         9  ...       759       760  \\\n",
      "Word                                                ...                       \n",
      "abdominal   0.011347  0.001995  0.076569 -0.106402  ...  0.007595  0.071308   \n",
      "abrupt      0.011351  0.001994  0.076571 -0.106401  ...  0.007594  0.071309   \n",
      "absent      0.011358  0.001990  0.076576 -0.106401  ...  0.007593  0.071316   \n",
      "accepté     0.011358  0.001990  0.076576 -0.106401  ...  0.007592  0.071319   \n",
      "accompagné  0.011358  0.001990  0.076576 -0.106402  ...  0.007592  0.071317   \n",
      "\n",
      "                 761       762       763       764       765       766  \\\n",
      "Word                                                                     \n",
      "abdominal   0.004354  0.067415 -0.031082  0.127922 -0.120320  0.033441   \n",
      "abrupt      0.004355  0.067417 -0.031078  0.127923 -0.120316  0.033444   \n",
      "absent      0.004357  0.067421 -0.031073  0.127921 -0.120305  0.033452   \n",
      "accepté     0.004355  0.067421 -0.031074  0.127921 -0.120306  0.033454   \n",
      "accompagné  0.004356  0.067420 -0.031074  0.127921 -0.120306  0.033453   \n",
      "\n",
      "                 767  Gender  \n",
      "Word                          \n",
      "abdominal   0.028320       1  \n",
      "abrupt      0.028319       1  \n",
      "absent      0.028314       1  \n",
      "accepté     0.028313       1  \n",
      "accompagné  0.028314       1  \n",
      "\n",
      "[5 rows x 769 columns]\n",
      "Saved adjective embeddings for XLM-Roberta-Base.\n",
      "Processing embeddings for mBERT-Base-Uncasedon adjectives...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped words due to out-of-vocabulary: 65819\n",
      "Sample embeddings for mBERT-Base-Uncased:\n",
      "                  0         1         2         3         4         5  \\\n",
      "Word                                                                    \n",
      "abandonné -0.516744  1.115343 -0.137685  0.288690 -1.494414  1.287974   \n",
      "abrité    -0.522401  1.099905 -0.139889  0.300243 -1.492713  1.210976   \n",
      "absent    -0.514369  1.121930 -0.141710  0.269820 -1.505412  1.276619   \n",
      "absolue    0.011467  0.250145  0.061106  0.259305 -0.326736 -0.070246   \n",
      "abusé     -0.446718  1.064334 -0.214545  0.285939 -1.405199  1.137035   \n",
      "\n",
      "                  6         7         8         9  ...       759       760  \\\n",
      "Word                                               ...                       \n",
      "abandonné -0.060082 -0.181060  0.312453  0.626785  ... -0.803875 -0.758321   \n",
      "abrité    -0.037263 -0.202397  0.297605  0.614302  ... -0.766316 -0.765899   \n",
      "absent    -0.070462 -0.178888  0.314820  0.636031  ... -0.786408 -0.755971   \n",
      "absolue    0.074515 -0.027836  0.128484 -0.165612  ... -0.400893 -0.448857   \n",
      "abusé     -0.021866 -0.161372  0.329763  0.573117  ... -0.589676 -0.808974   \n",
      "\n",
      "                761       762       763       764       765       766  \\\n",
      "Word                                                                    \n",
      "abandonné  0.056950 -0.745203  0.359301  0.039634  0.435784  0.052651   \n",
      "abrité     0.070742 -0.719379  0.356534  0.062858  0.440749  0.048649   \n",
      "absent     0.048855 -0.741050  0.339856  0.040067  0.432002  0.054243   \n",
      "absolue   -0.145628  0.001417 -0.089864  0.016787 -0.155388  0.223811   \n",
      "abusé      0.174701 -0.617589  0.311891  0.165922  0.441981 -0.032796   \n",
      "\n",
      "                767  Gender  \n",
      "Word                         \n",
      "abandonné -0.617461       1  \n",
      "abrité    -0.582272       1  \n",
      "absent    -0.612330       1  \n",
      "absolue   -0.397789       0  \n",
      "abusé     -0.556144       1  \n",
      "\n",
      "[5 rows x 769 columns]\n",
      "Saved adjective embeddings for mBERT-Base-Uncased.\n",
      "Processing embeddings for mBERT-Base-Casedon adjectives...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped words due to out-of-vocabulary: 66903\n",
      "Sample embeddings for mBERT-Base-Cased:\n",
      "                   0         1         2         3         4         5  \\\n",
      "Word                                                                     \n",
      "abandonné   0.347691 -0.534404  0.285921  0.136949  0.116014  0.097085   \n",
      "absent      0.349102 -0.534716  0.287126  0.137951  0.115974  0.096673   \n",
      "absolue     0.348001 -0.534657  0.285109  0.137048  0.116047  0.098042   \n",
      "accompagné  0.346162 -0.534618  0.283628  0.135667  0.115955  0.097196   \n",
      "acteur      0.347982 -0.535534  0.285630  0.136340  0.116589  0.098362   \n",
      "\n",
      "                   6         7         8         9  ...       759       760  \\\n",
      "Word                                                ...                       \n",
      "abandonné   0.028410  0.941686 -0.610105  0.365626  ...  1.083181 -0.627648   \n",
      "absent      0.028808  0.942350 -0.610411  0.365865  ...  1.082932 -0.628827   \n",
      "absolue     0.028200  0.942263 -0.610996  0.366071  ...  1.083382 -0.628778   \n",
      "accompagné  0.029485  0.942014 -0.609166  0.364672  ...  1.082163 -0.626313   \n",
      "acteur      0.026918  0.944549 -0.610987  0.365140  ...  1.083596 -0.628916   \n",
      "\n",
      "                 761       762       763       764       765       766  \\\n",
      "Word                                                                     \n",
      "abandonné  -0.914185 -0.227687  0.014775  0.266297 -0.035051 -0.018349   \n",
      "absent     -0.915998 -0.226723  0.015521  0.266541 -0.035532 -0.017326   \n",
      "absolue    -0.915236 -0.228800  0.015121  0.266707 -0.035564 -0.016557   \n",
      "accompagné -0.910960 -0.225263  0.014441  0.268445 -0.034868 -0.017802   \n",
      "acteur     -0.913714 -0.226106  0.014849  0.268381 -0.035064 -0.018621   \n",
      "\n",
      "                 767  Gender  \n",
      "Word                          \n",
      "abandonné  -0.363452       1  \n",
      "absent     -0.363338       1  \n",
      "absolue    -0.363444       0  \n",
      "accompagné -0.360760       1  \n",
      "acteur     -0.362838       1  \n",
      "\n",
      "[5 rows x 769 columns]\n",
      "Saved adjective embeddings for mBERT-Base-Cased.\n",
      "Processing embeddings for DistilBERT-Base-Casedon adjectives...\n",
      "Skipped words due to out-of-vocabulary: 66903\n",
      "Sample embeddings for DistilBERT-Base-Cased:\n",
      "                   0         1         2         3         4         5  \\\n",
      "Word                                                                     \n",
      "abandonné   0.054990 -0.175007  0.600365  0.063109  0.347803  0.057271   \n",
      "absent     -0.025028 -0.381208  0.329317  0.091050  0.146139  0.214463   \n",
      "absolue     0.218642 -0.069915  0.322719 -0.000733  0.376137  0.344041   \n",
      "accompagné  0.127270 -0.518326  0.730175  0.038970  0.373622  0.307569   \n",
      "acteur     -0.021606 -0.371622  0.665262 -0.194331  0.366626  0.062427   \n",
      "\n",
      "                   6         7         8         9  ...       759       760  \\\n",
      "Word                                                ...                       \n",
      "abandonné  -0.080132  0.140303  0.301362 -0.078795  ... -0.021097 -0.486755   \n",
      "absent     -0.119190  0.103213  0.012398 -0.340441  ... -0.217846 -0.780685   \n",
      "absolue     0.037056 -0.349811  0.137769  0.081258  ...  0.006548 -0.731869   \n",
      "accompagné -0.073275 -0.100136  0.325475 -0.168275  ...  0.103199 -0.252700   \n",
      "acteur     -0.139108  0.104430 -0.040968 -0.139353  ... -0.054394 -0.695458   \n",
      "\n",
      "                 761       762       763       764       765       766  \\\n",
      "Word                                                                     \n",
      "abandonné  -0.084778 -0.015682  0.127983  0.056532  0.296078  0.171975   \n",
      "absent     -0.297069  0.245319  0.125518  0.141758  0.325541  0.087028   \n",
      "absolue    -0.057335  0.162451  0.095056  0.060137  0.247958  0.276423   \n",
      "accompagné  0.024486 -0.117668  0.231183  0.159903  0.465871  0.061566   \n",
      "acteur     -0.194977  0.045950  0.192194  0.003353  0.671148 -0.217736   \n",
      "\n",
      "                 767  Gender  \n",
      "Word                          \n",
      "abandonné   0.013532       1  \n",
      "absent     -0.101140       1  \n",
      "absolue    -0.053248       0  \n",
      "accompagné  0.023985       1  \n",
      "acteur      0.012342       1  \n",
      "\n",
      "[5 rows x 769 columns]\n",
      "Saved adjective embeddings for DistilBERT-Base-Cased.\n"
     ]
    }
   ],
   "source": [
    "# Define model names\n",
    "model_names = {\n",
    "   \n",
    "   \"XLM-R_large\": \"xlm-roberta-large\",\n",
    "   \"XLM-Roberta-Base\": \"xlm-roberta-base\",\n",
    "   \"mBERT-Base-Uncased\": \"bert-base-multilingual-uncased\",\n",
    "   \"mBERT-Base-Cased\": \"bert-base-multilingual-cased\",\n",
    "    \"DistilBERT-Base-Cased\": \"distilbert-base-multilingual-cased\"\n",
    "\n",
    "}\n",
    "\n",
    "# Load adjective dataset\n",
    "adjs_cleaned = pd.read_csv(\"cleaned_adjs_gender.csv\")\n",
    "\n",
    "# Generate embeddings for each model\n",
    "for model_label, model_name in model_names.items():\n",
    "    print(f\"Processing embeddings for {model_label}on adjectives...\")\n",
    "    model, tokenizer = load_model_and_tokenizer(model_name)\n",
    "    embeddings_df = generate_embeddings(adjs_cleaned,model,tokenizer)\n",
    "    \n",
    "    # Set Word as Index\n",
    "    embeddings_df.set_index(\"Word\", inplace=True)\n",
    "\n",
    "    # Display sample\n",
    "    print(f\"Sample embeddings for {model_label}:\")\n",
    "    print(embeddings_df.head())\n",
    "\n",
    "    # Save outputs\n",
    "    embeddings_df.to_csv(f\"{model_label}_adjective_embeddings_with_gender.csv\")\n",
    "    embeddings_df.to_pickle(f\"{model_label}_adjective_embeddings.pkl\")\n",
    "\n",
    "    print(f\"Saved adjective embeddings for {model_label}.\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # File path to the nouns dataset\n",
    "file_path = r\"C:\\Users\\user1\\Desktop\\HarvestWE-main\\mBERT-Base-Uncased_adjective_embeddings_with_gender.csv\"\n",
    "\n",
    "dataset = pd.read_csv(file_path)\n",
    "print(dataset.head())\n",
    "print(dataset.columns)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
